{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fopen = open('../dataset/digit/train.csv', 'r')\n",
    "train_df = pd.read_csv(fopen)\n",
    "fopen.close()\n",
    "fopen = open('../dataset/digit/test.csv', 'r')\n",
    "test_df = pd.read_csv(fopen)\n",
    "fopen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "----------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "print '----------------------'\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_label = train_df.label.values\n",
    "train_df.drop(['label'], inplace=True, axis=1)\n",
    "\n",
    "train_arr = train_df.values.astype(np.float32)\n",
    "test_arr = test_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_arr, train_label, test_size=0.05, random_state=42)\n",
    "n_sample = X_train.shape[0]\n",
    "y_train = label_binarize(y_train, range(10))\n",
    "y_test = label_binarize(y_test, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_fc_layer(input, input_size, output_size, activation=None):\n",
    "    input = tf.reshape(input, [-1, input_size]) \n",
    "    w = tf.Variable(tf.random_normal([input_size, output_size], dtype=tf.float32))\n",
    "    b = tf.Variable(tf.random_normal([1, output_size], dtype=tf.float32))\n",
    "    out = tf.matmul(input, w) + b\n",
    "    return activation(out) if activation else out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_conv_layer(x, filter_size, activation=None):\n",
    "    w = tf.Variable(tf.random_normal(filter_size), dtype=tf.float32)\n",
    "    conv = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    b = tf.Variable(tf.random_normal([1, filter_size[-1]], dtype=tf.float32))\n",
    "    out = conv + b\n",
    "    return activation(out) if activation else out\n",
    "\n",
    "def add_pool_layer(x, activation=None):\n",
    "    pool = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return activation(pool) if activation else pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def acc(pred, target):\n",
    "    return (np.argmax(pred, axis=1) == np.argmax(target, axis=1)).sum() / float(target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "reshape = tf.reshape(x, [-1, 28, 28, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1 = add_conv_layer(reshape, [5, 5, 1, 32], tf.nn.relu)\n",
    "l2 = add_pool_layer(l1)\n",
    "\n",
    "l3 = add_conv_layer(l2, [5, 5, 32, 64], tf.nn.relu)\n",
    "l4 = add_pool_layer(l3)\n",
    "\n",
    "l5 = add_fc_layer(l4, 7*7*64, 1024, tf.nn.relu)\n",
    "drop = tf.nn.dropout(l5, keep_prob=keep_prob)\n",
    "l6 = add_fc_layer(drop, 1024, 10)\n",
    "\n",
    "soft_max = tf.nn.softmax(l6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(l6, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(2e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=0.18, loss=1127768832.0, valid_acc=0.169047619048\n"
     ]
    }
   ],
   "source": [
    "ss = tf.InteractiveSession()\n",
    "ss.run(tf.initialize_all_variables())\n",
    "for step in xrange(20):\n",
    "    start = step * 100 % X_train.shape[0]\n",
    "    end = (step * 100 + 100) % X_train.shape[0]\n",
    "    xs, ys = X_train[start:end], y_train[start:end]\n",
    "    ss.run(opt, feed_dict={x : xs, y : ys, keep_prob : 0.5})\n",
    "    if step % 50 == 0:\n",
    "        train_result = ss.run(soft_max, feed_dict={x : xs, keep_prob : 1})\n",
    "        test_result = ss.run(soft_max, feed_dict={x : X_test, keep_prob : 1})\n",
    "        ls = ss.run(loss, feed_dict={x : xs, y : ys, keep_prob : 1})\n",
    "        print \"train_acc={0}, loss={1}, valid_acc={2}\".format(acc(train_result, ys), ls, acc(test_result, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict = np.array([])\n",
    "for i in xrange(test_arr.shape[0] / 1000):\n",
    "    res = ss.run(soft_max, feed_dict={x : test_arr[i * 1000: i * 1000 + 1000], keep_prob : 1})\n",
    "    predict = np.append(predict, np.argmax(res, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
