{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fopen = open('../../input/digit/train.csv', 'r')\n",
    "train_df = pd.read_csv(fopen)\n",
    "fopen.close()\n",
    "fopen = open('../../input/digit/test.csv', 'r')\n",
    "test_df = pd.read_csv(fopen)\n",
    "fopen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "----------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "print '----------------------'\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_label = train_df.label.values\n",
    "train_df.drop(['label'], inplace=True, axis=1)\n",
    "\n",
    "train_arr = train_df.values.astype(np.float32) / 255.0\n",
    "test_arr = test_df.values.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_arr, train_label, test_size=0.05, random_state=42)\n",
    "n_sample = X_train.shape[0]\n",
    "y_train = label_binarize(y_train, range(10))\n",
    "y_test = label_binarize(y_test, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_fc_layer(input, input_size, output_size, activation=None):\n",
    "    input = tf.reshape(input, [-1, input_size]) \n",
    "    w = tf.Variable(tf.truncated_normal([input_size, output_size], stddev=0.1, dtype=tf.float32))\n",
    "    b = tf.Variable(tf.truncated_normal([1, output_size], stddev=0.1, dtype=tf.float32))\n",
    "    out = tf.matmul(input, w) + b\n",
    "    return activation(out) if activation else out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_conv_layer(x, filter_size, activation=None):\n",
    "    w = tf.Variable(tf.truncated_normal(filter_size, stddev=0.1), dtype=tf.float32)\n",
    "    conv = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    b = tf.Variable(tf.truncated_normal([1, filter_size[-1]], stddev=0.1, dtype=tf.float32))\n",
    "    out = conv + b\n",
    "    return activation(out) if activation else out\n",
    "\n",
    "def add_pool_layer(x, activation=None):\n",
    "    pool = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return activation(pool) if activation else pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def acc(pred, target):\n",
    "    return (np.argmax(pred, axis=1) == np.argmax(target, axis=1)).sum() / float(target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "reshape = tf.reshape(x, [-1, 28, 28, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1 = add_conv_layer(reshape, [5, 5, 1, 32], tf.nn.relu)\n",
    "l2 = add_pool_layer(l1)\n",
    "\n",
    "l3 = add_conv_layer(l2, [5, 5, 32, 64], tf.nn.relu)\n",
    "l4 = add_pool_layer(l3)\n",
    "\n",
    "l5 = add_fc_layer(l4, 7*7*64, 1024, tf.nn.relu)\n",
    "drop = tf.nn.dropout(l5, keep_prob=keep_prob)\n",
    "l6 = add_fc_layer(drop, 1024, 10)\n",
    "\n",
    "soft_max = tf.nn.softmax(l6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(l6, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7fe2d127bc10>> ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=0.15, loss=784.794799805, valid_acc=0.130952380952\n",
      "train_acc=0.87, loss=104.557807922, valid_acc=0.83380952381\n",
      "train_acc=0.895, loss=70.4955749512, valid_acc=0.902857142857\n",
      "train_acc=0.91, loss=58.3571853638, valid_acc=0.922380952381\n",
      "train_acc=0.895, loss=58.1383361816, valid_acc=0.932380952381\n",
      "train_acc=0.935, loss=39.9743118286, valid_acc=0.94\n",
      "train_acc=0.95, loss=30.6232070923, valid_acc=0.947142857143\n",
      "train_acc=0.96, loss=27.3180236816, valid_acc=0.952857142857\n",
      "train_acc=0.955, loss=34.3939628601, valid_acc=0.960476190476\n",
      "train_acc=0.965, loss=26.5595169067, valid_acc=0.958571428571\n",
      "train_acc=0.95, loss=22.8779373169, valid_acc=0.960952380952\n",
      "train_acc=0.955, loss=21.6869277954, valid_acc=0.964285714286\n",
      "train_acc=0.97, loss=23.3331546783, valid_acc=0.968095238095\n",
      "train_acc=0.96, loss=28.4831047058, valid_acc=0.969523809524\n",
      "train_acc=0.99, loss=11.6823406219, valid_acc=0.966666666667\n",
      "train_acc=0.975, loss=18.5878601074, valid_acc=0.970476190476\n",
      "train_acc=0.97, loss=20.1019897461, valid_acc=0.974285714286\n",
      "train_acc=0.98, loss=23.8757648468, valid_acc=0.972380952381\n",
      "train_acc=0.97, loss=19.017906189, valid_acc=0.970476190476\n",
      "train_acc=0.98, loss=10.0352649689, valid_acc=0.97380952381\n",
      "train_acc=0.975, loss=15.762298584, valid_acc=0.974285714286\n",
      "train_acc=0.995, loss=7.35153007507, valid_acc=0.975238095238\n",
      "train_acc=0.965, loss=19.1164035797, valid_acc=0.97380952381\n",
      "train_acc=0.985, loss=11.3522500992, valid_acc=0.976666666667\n",
      "train_acc=0.985, loss=7.16021537781, valid_acc=0.977142857143\n",
      "train_acc=0.985, loss=7.15684843063, valid_acc=0.979523809524\n",
      "train_acc=0.985, loss=7.4987154007, valid_acc=0.978571428571\n",
      "train_acc=0.99, loss=8.92902946472, valid_acc=0.98\n",
      "train_acc=0.985, loss=11.001748085, valid_acc=0.978095238095\n",
      "train_acc=0.97, loss=11.5471973419, valid_acc=0.977619047619\n",
      "train_acc=0.99, loss=4.82589244843, valid_acc=0.979047619048\n",
      "train_acc=0.995, loss=8.3585691452, valid_acc=0.981428571429\n",
      "train_acc=0.99, loss=10.3261213303, valid_acc=0.980952380952\n",
      "train_acc=0.985, loss=7.34612560272, valid_acc=0.980952380952\n",
      "train_acc=0.99, loss=5.18446588516, valid_acc=0.98\n",
      "train_acc=0.995, loss=7.98427963257, valid_acc=0.981428571429\n",
      "train_acc=1.0, loss=4.89861488342, valid_acc=0.980952380952\n",
      "train_acc=0.985, loss=5.89538764954, valid_acc=0.981428571429\n",
      "train_acc=0.985, loss=7.42801094055, valid_acc=0.981428571429\n",
      "train_acc=0.995, loss=4.17158126831, valid_acc=0.983333333333\n"
     ]
    }
   ],
   "source": [
    "ss = tf.InteractiveSession()\n",
    "ss.run(tf.initialize_all_variables())\n",
    "for step in xrange(2000):\n",
    "    start = step * 200 % X_train.shape[0]\n",
    "    end = (step * 200 + 200) % X_train.shape[0]\n",
    "    xs, ys = X_train[start:end], y_train[start:end]\n",
    "    ss.run(opt, feed_dict={x : xs, y : ys, keep_prob : 0.5})\n",
    "    if step % 50 == 0:\n",
    "        train_result = ss.run(soft_max, feed_dict={x : xs, keep_prob : 1})\n",
    "        test_result = ss.run(soft_max, feed_dict={x : X_test, keep_prob : 1})\n",
    "        ls = ss.run(loss, feed_dict={x : xs, y : ys, keep_prob : 1})\n",
    "        print \"train_acc={0}, loss={1}, valid_acc={2}\".format(acc(train_result, ys), ls, acc(test_result, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = ss.run(soft_max, feed_dict={x : test_arr, keep_prob : 1})\n",
    "np.argmax(res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict = np.array([])\n",
    "for i in xrange(test_arr.shape[0] / 1000):\n",
    "    res = ss.run(soft_max, feed_dict={x : test_arr[i * 1000: i * 1000 + 1000], keep_prob : 1})\n",
    "    predict = np.append(predict, np.argmax(res, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
